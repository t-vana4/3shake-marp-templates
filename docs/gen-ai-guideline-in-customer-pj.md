# 顧客案件における生成AI利用ガイドライン

- 目次

<aside>
💡

### エグゼクティブサマリ

このガイドラインでみなさんに伝えたいポイントを3つにまとめました。まずはこちらをご覧ください！

1. **AIは「武器」である**
AIを戦略的な「武器」として活用し、顧客への提供価値を飛躍的に高めていくことが、私たちの目的です。簡単なコーディングやバグ修正、文書作成はAIに任せ、私たちは顧客の課題解決に繋がるシステム設計やコンサルティングといった、より付加価値の高い創造的な仕事に時間を使っていきましょう。このガイドラインは、そのための「攻めのガードレール」です。
2. **成果物責任は「人」にある**
AIは優秀なアシスタントですが、その生成物はあくまで「素材」に過ぎません。生成物の内容を鵜呑みにせず、ピアレビューや脆弱性スキャンといった必須プロセスを必ず遵守してください。AIに作業を丸投げするのではなく、AIを使って作業を加速させる意識が重要です。成果物に対する最終的な責任は、AIではなく、それを利用している私たち自身にあります。
3. **「顧客からの信頼」がすべて**
会社の信頼を守るために、顧客と合意した範囲内でAIを利用してください。私たちのビジネスは、顧客との信頼関係の上に成り立っています。それを壊すような行動は絶対にしないでください。万が一のことがあった場合、信頼を失うのはあなた個人ではなく会社なのです。
</aside>

---

## 1. はじめに

生成AIを顧客案件で積極的に利用していくための指針として、本ガイドラインを策定します。

このガイドラインは生成AIの利用を制限するためのものではありません。顧客案件という機密性の高い環境において、エンジニアのみなさんが生成AIを「安全」かつ「戦略的」に活用し、より付加価値の高い仕事をしてもらうための「羅針盤」です。

私たちの目的は、生成AIの力を最大限に活用することで、以下 2 つの要件を高いレベルで両立させることにあります。

- **提供価値の向上:** 簡単なコーディングやバグ修正、文書作成は生成AIに任せ、より創造的で付加価値の高いシステム設計やコンサルティングに注力する
- **信頼関係の維持・強化:** 強固なセキュリティを確保した上で生成AIを利用し、顧客との信頼関係を維持・強化する

エンジニアのみなさんが生成AIという強力な武器を安心して使いこなし、他社には真似できないスピードと品質で顧客価値を最大化するための「攻めのガードレール」として、このガイドラインを活用してください。

## 2. 基本方針

顧客案件における生成AIの基本的な利用方針として、利用を推奨する作業と利用を禁止/制限する作業を次のように定義します。

| 区分 | 方針 | 具体的な作業の例 |
| --- | --- | --- |
| **利用奨励作業** | **積極的に生成AIを活用し、生産性と品質を向上させましょう** | • **コード生成・リファクタリング:** 定型的なCRUD操作、テストコード、設定ファイルの生成 など
• **ドキュメント作成:** 技術仕様書、API仕様書、運用手順書の下書き作成 など
• **問題解決・デバッグ:** エラーの原因分析、解決策の提案 など
• **学習・スキルアップ:** 新技術の理解、コードレビューの観点整理 など
• **情報収集:** 一般的な技術情報やビジネス情報の収集 など |
| **利用禁止/制限作業** | **顧客の信頼やアウトプットの品質を損なう可能性があるため避けましょう** | • **顧客固有の機密情報を含む作業:** 社外秘情報を含む資料の分析、コア業務に関するソースコードの解析 など
• **本番環境に影響を及ぼす作業:** 自動デプロイ、本番データベースの直接操作 など
• **無検証での変更マージ:** 自動承認（Auto-approve）機能による自動マージ など
• **セキュリティ関連の実装:** 認証・認可ロジック、暗号化処理 など
• **顧客との合意が必要な設計変更:** アーキテクチャの大幅な変更 など |

## 3. 利用可能なAIツールの判断基準

顧客案件で利用可能なAIツールは、**会社として契約し許可したツールに限定**します。利用可能なツールの一覧と各ツールの利用上の注意点は、[**承認済みAIツールリスト**](https://www.notion.so/AI-224b1e6bcbc2808a8a04cb0b7fa13820?pvs=21) を参照してください。**リストにないツールは、たとえセルフチェックで安全だと判断しても利用厳禁です。**

ツールの利用可否を会社が判断する際の基準は次のとおりです。

### **🔒 セキュリティ要件**

- **データ非学習保証:** 入力したデータ（プロンプト、コンテキスト）が、AIモデルの学習に利用されないことが契約レベルで明確に保証されている。
- **暗号化通信:** すべての通信が TLS で暗号化されている。
- **ユーザー認証**: 3-shake の Google アカウントを使って認証できる。
- **データ保存ポリシーの明示:** 保存データの暗号化方針や保存期間、削除プロセスが明示されている。
- **アクセスログの取得:** すべての操作ログ（誰が、いつ、どのような操作を行ったか）が監査可能な形で取得できる。
- **地政学的リスクの回避:** ツールの開発国が中国またはロシアではない。

### **🏢 ガバナンス要件**

- **コンプライアンス認証:** SOC2、ISO27001等の適切なセキュリティ認証を取得している。
- **企業向けプラン:** 個人向けではなく、企業向けのプランで契約できる。

## 4. 情報セキュリティ遵守事項

顧客からの信頼を守るために、全員が以下のルールを遵守してください。**万が一のことがあった場合、信頼を失うのは個人ではなく会社です。**

### 🚫 入力禁止情報

以下の情報は、その一部であっても、会社が許可したAIツール以外への入力を禁止します。

- **顧客のソースコード、設定ファイル（Terraform, Kubernetesマニフェスト等）**
- **顧客システムの構成情報、ネットワーク図、IPアドレス、ドメイン名**
- **APIキー、パスワード、証明書などのクレデンシャル情報**
- **顧客から預託されたデータ（個人情報、決済情報など）**
- **顧客の社内情報（従業員名、メールアドレス、非公開のプロジェクト名、資料）**
- **当社と顧客、または第三者との間で締結したNDA（秘密保持契約）対象の情報**

### 🚫 禁止操作

プロンプト入力以外でも、以下の操作は禁止です。

- **レビュー不能な自動化の禁止:** 人間の開発者がレビューできない、またはレビューを省略するようなAIの自動承認（Auto-approve）機能や自動マージ機能の利用。
- **安易なツール連携の禁止:** 開発元が不明、あるいは非公式な外部ツール（IDEプラグイン, ブラウザ拡張機能, MCPサーバーなど）を介して、入力禁止情報に該当する情報を意図せずAIサービスに送信すること。

### ✅ プロンプト作成時のセルフチェックリスト

プロンプトを送信する前に、一呼吸おいて必ず自問してください。

- [ ]  顧客名、システム名、サーバー名などの固有名詞を完全に削除・抽象化したか？
- [ ]  ソースコードを渡す場合、それ単体では顧客やシステムを特定できない、汎用的なコード断片になっているか？
- [ ]  エラーログを渡す場合、IPアドレス、ユーザー名、メールアドレスなどの機密情報が含まれていないか？
- [ ]  このプロンプトの内容全体を、インターネットの公開掲示板（Stack Overflowなど）にそのまま投稿しても、情報漏洩のリスクはゼロと言い切れるか？

## 5. 生成物の取り扱いと品質担保

AIが生成する生成物には、利用者の意図とは異なる情報や想定外の不備が含まれるリスクがあります。AIの生成物を成果物に組み入れる際には、人間による厳格な品質保証プロセスを経る必要があります。

### ⚠️ 生成物が内包するリスク

| **リスク分類** | **具体的なリスク** | **内容** |
| --- | --- | --- |
| **セキュリティリスク** | **脆弱なコードの生成** | SQLインジェクションやクロスサイトスクリプティング（XSS）など、典型的な脆弱性を含んだコードが生成されるリスク。 |
|  | **不適切な秘密情報のハードコーディング** | 本来は外部から注入すべきAPIキーやパスワードのサンプルを、コード内に直接書き込んでしまうリスク。 |
| **品質・保守性リスク** | **古い・非推奨な技術の利用** | 現在はメンテナンスされていないライブラリや、非推奨（deprecated）となった古いバージョンの関数・APIを使用してしまうリスク。 |
|  | **もっともらしい嘘（ハルシネーション）** | 存在しない関数やライブラリ、設定項目などを、あたかも存在するかのように生成してしまうリスク。 |
|  | **潜在的なバグの混入** | 一見正しく動作するように見えて、特定の条件下やエッジケースで問題を引き起こすロジックが埋め込まれるリスク。 |
|  | **低品質・低可読なコード** | プロジェクトのコーディング規約に沿っていなかったり、過度に複雑で将来の保守を困難にするコードが生成されるリスク。 |
| **法務・コンプライアンスリスク** | **意図しないライセンス違反** | GPL/AGPLなど、利用することでプロダクト全体に強いライセンス制約を課してしまうコードを、その旨を明示せずに生成してしまうリスク。 |
|  | **著作権の侵害** | インターネット上で学習した、特定の個人や企業が著作権を持つコードを、無許諾でそのまま、あるいは酷似した形で生成してしまうリスク。 |

### 🏁 品質保証プロセス

1. **担当者による理解と修正:**
生成されたコードの意図を完全に理解し、プロジェクトの要件やコーディング規約に合わせて自身の責任で修正・最適化する。
2. **ピアレビュー:**
チームメンバーによる通常のコードレビューを必ず実施する。レビュー依頼時には「AIにて生成したコードを含む」ことを明記し、レビュアーはその前提で、より慎重な確認を行う。
3. **静的解析・脆弱性等スキャン:**
CI/CDパイプラインに SAST (Static Application Security Test) ツールや SCA (Software Composition Analysis) ツールなどを組み込み、脆弱性やライセンス違反などがないかスキャンする。
4. **動作確認:**
テスト環境で、要求仕様を満たすか、デグレが発生しないかなど、十分な動作確認を行う。

### ℹ️ リスクに応じたプロセスの最適化

- 本番利用するコードやセキュリティに影響する設定ファイルの変更などは、上記品質保証プロセスの**全工程を原則必須とします。**
- 一方で、仮に不備があっても影響が限定的な場合（検証用コードの生成や技術ドキュメントの骨子作成など）や、工数等の制約がある場合などは、**顧客と合意できている限りにおいて、**一部プロセスの省略・簡略化を許可します。その場合、省略・簡略化するプロセスとその理由を必ずドキュメント（顧客との打ち合わせ議事録など）に残しておいてください。

### 📜 生成物の著作権と納品

- **著作権の考え方:** 生成AIの生成物は、開発支援ツールを利用した成果物とみなし、その著作権は（顧客との契約に基づき）原則として当社または顧客に帰属します。ただし、生成物が既存のオープンソースコード等と酷似している可能性もゼロではないため、常に注意が必要です。
- **顧客への明示義務:** 生成AIを利用した成果物作成は私たちの開発プロセスの一部であるため、顧客への納品物に対して、AIを利用して作成した旨を特別に表示する必要は原則ありません。ただし、顧客との契約で別途定めがある場合は、必ずそれに準拠してください。
    
    参考: [https://www.bunka.go.jp/seisaku/bunkashingikai/chosakuken/pdf/94037901_01.pdf](https://www.bunka.go.jp/seisaku/bunkashingikai/chosakuken/pdf/94037901_01.pdf)
    

## 6. 顧客との合意形成

AI活用の透明性を確保し、顧客と良好な関係を築くために、AIツールの利用方針を事前に顧客に説明し、合意形成をしてください。

### 🆗 AI利用許容度レベル

| レベル | 呼称 | 利用範囲 | 前提条件・注意点 |
| --- | --- | --- | --- |
| **レベル0** | **利用禁止** | AIツールの一切の利用を禁止する。 | ・プロジェクトに関連するすべての業務において、生成AIの利用を禁止する。
・契約書で明確に規定されている場合に適用する。 |
| **レベル1** | **限定的な利用** | 顧客情報に一切触れない一般的な技術調査や検証用ソースコードの生成などに限り、会社が標準的に許可しているAIツール* を利用できる。 | ・プロジェクトのソースコードや資料など、顧客から預託された情報をAIに入力することは禁止する。
・契約書で明確に規定されている場合に適用する。 |
| **レベル2** | **標準的な利用** | 本ガイドラインのルールに則り、会社が標準的に許可しているAIツール* を利用できる。 | ・当社の標準であり、顧客に最初に提案する推奨レベル。
・契約書に規定が無い場合は、このレベルを適用する。 |
| **レベル3** | **高度な利用** | 本ガイドラインのルールに則った上で、会社が案件用に個別に契約したAIツール、または会社に利用を申請して貸与されたAIツールを利用できる。 | ・顧客からの明確な許諾が必要。
・利用するAIツールの概要を顧客に説明し合意を得る必要がある。 |
| **レベル4** | **戦略的な利用** | 本ガイドラインのルールに準拠しないツールや用途であっても、顧客と合意した上で積極的に利用できる。 | ・顧客との間でAI活用に関する個別の覚書や契約を締結。
・顧客自身もAI活用に積極的で、共同で生産性向上を目指す場合に適用する。 |

* **会社が標準的に許可しているAIツール:** Geake, Google Gemini （3-shake の Google アカウントで利用）, Google NotebookLM （3-shake の Google アカウントで利用）

### 🤝 合意形成の基本

- **事前説明の徹底**
    - プロジェクト開始時（または適切なタイミング）で、プロジェクトマネージャー（PM）または担当営業から顧客に対して、本ガイドラインに準拠した安全な範囲で、開発の生産性・品質向上のために生成AIを利用する可能性があることを説明してください。
    - AI利用許容度レベルについて顧客に説明し、どのレベルまでなら許容できるかを確認してください。
- **説明に含めるべきポイント**
    - **利用目的:** 生産性や付加価値の向上を目的とすること。
    - **利用範囲:** コード生成やドキュメント作成などの用途で利用すること。
    - **安全対策:** 顧客のソースコードや機密情報を、外部のAIモデルの学習等に利用されるような形で入力することは絶対にないこと。
    - **品質担保:** 生成されたコードは、必ず人間のエンジニアによる厳格なレビュープロセスを経てから導入すること。
- **合意形成のポイント**
    - **顧客のセキュリティポリシー確認:** 可能であれば、顧客のAI利用に関する制限事項を事前に確認しておく。
    - **ツールの承認:** 使用予定のAIツールの概要を顧客に説明し承諾を得る。
    - **報告・相談体制の確立:** AI利用に関する報告や相談を受け付ける窓口を設定しておく。

## 7. インシデント発生時の対応

万が一、情報漏洩や著作権侵害などが発生、またはその可能性を認知した場合は、以下のルールに従って速やかに行動してください。

- **報告義務**
    - すべての従業員は、インシデントまたはその可能性を認知した場合、直ちに報告する義務があります。
    - 自己判断で問題を隠蔽したり、報告を遅らせたりすることは、被害を拡大させる恐れがあるため絶対にやめてください。
- **報告ルート**
    - **第一報:** プロジェクトマネージャー（PM）, 部長, チームリーダーに Slack の DM で報告してください。
    - **エスカレーション:** 報告を受けた PM と部長は、報告者に直ちに事実を確認した上で情シスにエスカレーションし、インシデント対応の指揮を依頼してください。
    - **顧客報告:** 情シスと経営層で顧客への報告方針をすみやかに決定し、顧客責任者に状況を報告してください。
    - **対策検討:** 会社レベルでの謝罪や賠償が必要になる場合は、法務等も巻き込んで対策を検討します。
- **報告内容**
    - 混乱を避けるため、以下の情報を可能な限り正確に報告してください。
        - **いつ（When）:** 問題を認知した日時
        - **どこで（Where）:** 利用したツール、PC など
        - **誰が（Who）:** AIツールを操作した人
        - **何を（What）:** 問題となった操作（プロンプト、生成物など）の概要
        - **なぜ（Why）:** その操作を行った目的
        - **どのように（How）:** 発覚の経緯
- **注意点**
    - 報告後、PM からの指示があるまで、関連するデータやログを削除したり、環境を変更したりしないでください。

## 8. 困ったときは

このガイドラインの解釈やツールの利用可否で迷ったら、一人で悩まず、PMや生成AI利活用推進担当に相談してください。

## 9. 本ガイドラインの取り扱いについて

生成AIを取り巻く状況は、日々ものすごいスピードで変化しています。このガイドラインが常に実用的であり続けるために、3ヶ月に一度、定期的な見直しを行います。

---

- 更新履歴
    
    
    | 更新日 | 更新者 | 更新内容 |
    | --- | --- | --- |
    | 2025年7月3日  | @Hajime Tachibana  | 新規作成 |
    |  |  |  |
    |  |  |  |